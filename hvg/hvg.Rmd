---
title: "Find Highly Variable Genes"
output:
  html_document:
    df_print: paged
    toc: yes
    number_sections: true
    toc_float: true
    self_contained: true
    mathjax: default
    code_download: true
---




# Load Packages

```{r}
library(ggplot2)
library(pbmcapply) # parallelization
library(quantreg)  # quantile regression with rq.wfit
library(parallelDist)
```



# Load data
On the CITEseq data, we play around with HVGs (highly variable genes), i.e.
superpoissonian genes.

```{r loadCITE}
citeDIR <- "~/sds/sd17l002/p/scRNAseq_datasets/CITEseq_NatMethods_2017/data/"
rna_file <- paste0(citeDIR, "GSE100866_CBMC_8K_13AB_10X-RNA_umi.csv.gz")
adt_file <- paste0(citeDIR, "GSE100866_CBMC_8K_13AB_10X-ADT_umi.csv.gz")

rawC <- as.matrix(read.csv(gzfile(rna_file), row.names = 1))
prot <- as.matrix(read.csv(gzfile(adt_file), row.names = 1))

# exclude mouse cells:
is_mouse <- colSums(rawC[grepl("MOUSE", rownames(rawC)),]) / colSums(rawC) > .1
rawC <- rawC[grepl("HUMAN", rownames(rawC)), ! is_mouse]
prot <- prot[, ! is_mouse]
```




# RNA data: normalization

```{r}
normC <- apply( rawC, 2, function(col) {
  (sqrt(col+3/8)-sqrt(3/8)) / sqrt(sum(col))
})

```




# Protein data: normalization and Cell identities
```{r}
# simplifying Seurat's code to compute Centered Log Ratio (CLR):
norm_prot <- apply(prot, 1, function(x) {
  log1p( (x) /
                          (exp(sum(log1p((x)[x > 0]), na.rm = TRUE)/length(x + 1))) ) })


 # exclude NK and monos:
  plot(norm_prot[, "CD11c"], norm_prot[, "CD56"], pch =20, cex=.1, 
       main = "CITEseqs protein data\nto exclude NKs (CD56) and myeloid cells (CD11c)")
  lin_neg <- norm_prot[, "CD56"] < 1.1   & norm_prot[, "CD11c"] < 1 
 
# exclude erythrocytes. No good protein marker available, we use RNA for it:
  not_ery <- normC["HUMAN_HBB", ]  < .05  &
             normC["HUMAN_HBG2", ] < .05 &
             normC["HUMAN_HBA1", ] < .04 
# same for platelets / megakaryocytes:
  not_platelet <- normC["HUMAN_GP9", ] < .005 &
                  normC["HUMAN_PF4", ] < .005 &
                  normC["HUMAN_PPBP", ] < .005 
  
  
# B and T cells:
  has_B_markers <- norm_prot[, "CD19"] > 2  &  norm_prot[, "CD3"] < .5
  has_T_markers <- norm_prot[, "CD19"] < 1.5  &  norm_prot[, "CD3"] > 1
  plot(norm_prot[, "CD3"], norm_prot[, "CD19"], pch =20, col =
         rgb(has_B_markers, has_T_markers, .7 *lin_neg),
       main = "B and T cells in red and green\nCD56-CD11c- in blue\nPick cells with mixture colors")

  
    
  isBcell <- has_B_markers & lin_neg & not_ery & not_platelet
  isTcell <- has_T_markers & lin_neg & not_ery & not_platelet

  
  
  has_CD4 <- norm_prot[, "CD4"] > 1  &  norm_prot[, "CD8"] < 1
  has_CD8 <- norm_prot[, "CD4"] < .5  &  norm_prot[, "CD8"] > 3
  isCD4Tcell <- isTcell & has_CD4
  isCD8Tcell <- isTcell & has_CD8
   
  plot(norm_prot[, "CD4"], norm_prot[, "CD8"], pch=20, cex=.4,
       col = rgb(0, isCD4Tcell, isCD8Tcell), 
       main = "CD4 and CD8 T cells\nselected amongst T cells picked above")  
  
  
Ts <- isCD4Tcell | isCD8Tcell
```




# getHVG function
```{r}
## bug report for below function(s):
  #
  #  This function is terrible coding practice; rewrite it completely!
  #
  #  rowMeans(rawC) and allM is redundant computation, that's uncritical but not elegant
  #
  #  everytime you run it, different genes get selected due to stochastic poisson.
  #  We'll probably find an analytic solution eventually anyways that should fix it.

                                                  ##

VMRstats <- function(mat = rawC, nbin_qreg = 75) {
  cs <- colSums(mat) 
  
  # Simon wants to filter out low-abundance genes. A very conservative cutoff is
  # the mean resulting from 1 small cell (nUMI = 500) having an UMI of 1, the rest 0s:
  threshold <- mean(c(1/500,  rep(0, ncol(rawC[, Ts])-1)))
     # used by rawC
     # also used by Poisson raw counts below
    print("Simulate Poisson Counts...")
  # estimate each gene's true mean and var - for this we normalize with library size:
    normC <- t( t(mat) / cs)
    normC <- normC[rowMeans(normC) > threshold,]
    allM <- apply(normC, 1, mean)
    allV <- apply(normC, 1, var)
  
  
  # simulate poisson raw counts relevant to our data (i.e. using allM):
    nc <- ncol(mat)
    pCounts <- do.call(rbind,
                       pbmclapply(allM, function(mu) {rpois(nc, lambda = mu * cs)},
                                  mc.cores=4) )
    # superfluous, here because I used to punch these into Seurat:
    rownames(pCounts) <- paste0("poisson_", 1:nrow(pCounts))
    colnames(pCounts) <- paste0("Cell_", 1:ncol(pCounts))
  
    print("Normalize Poisson Counts...")
  # as with real counts:
    normP <- t( t(pCounts) / cs)
    allMP <- apply(normP, 1, mean)
    allVP <- apply(normP, 1, var)
    # x,y for ease of typing. threshold also prevents -Inf values, defensive progr.:
    x <- log(allMP[allMP > threshold])
    y <- log(allVP[allMP > threshold] / allMP[allMP > threshold])
  
  print("Fit VMR-mean relationship...")
  # going over all x takes long, so we fit the VMR-mean relationship in bins:
  xrange <- range(x) # log(c(max(1e-9, min(allM), min(allMP)), max(max(allM), max(allMP))))
  bin_x <- seq(xrange[1], xrange[2], length.out = nbin_qreg)
  # random poisson by chance might not cover the extreme values:
  bin_x <- c(log(min(allM)), bin_x, log(max(allM)))
  
  # Simon's local quantile fit (faster using matrix notation, `mm`)
  mm <- cbind( Intercept = 1, X = x, X2 = x^2 )
  yfit <- do.call(rbind, pbmclapply( bin_x, function(xp)
    {
        fit        <- rq.wfit( mm, y, .75, dnorm( x, mean=xp, sd=2 ) )
        fit_median <- rq.wfit( mm, y, .5, dnorm( x, mean=xp, sd=2 ) )
        c(bin_x = xp,
          q75= fit$coefficients %*% c( 1, xp, xp^2 ),
          median = fit_median$coefficients %*% c( 1, xp, xp^2 ))
    } )  )
  
  # interpolate Poisson median and quantile for each gene: 
  all_y<- do.call(data.frame,
                 c( 
                   poisson_medians <- approx(x = yfit[, "bin_x"],
                                             y = yfit[, "median"],
                                             xout = log(allM)),
                   poisson_q75     <- approx(x = yfit[, "bin_x"],
                                             y = yfit[, "q75"],
                                             xout = log(allM)) ) )
  # return final result:
  data.frame(
      log_Gene_Mean         = all_y[, 1],
      log_Gene_VMR          = log(allV / allM),
      log_PoissonVMR_median = all_y[, 2],
      log_PoissonVMR_q75    = all_y[, 4],
      IQR_of_logged_VMR         = 2 * (all_y[, 4] - all_y[, 2]),
      row.names = rownames(all_y)
    )
  } 


getHVG <- function(vmrstats = VMRstats(rawCounts), IQRs = 10) {
  # returns genes that are more than n IQRs away (default: n = 10).
  hvg  <- vmrstats$log_Gene_VMR >
         vmrstats$log_PoissonVMR_median + IQRs * vmrstats$IQR_of_logged_VMR
  return(vmrstats[hvg, ])
}


v <- VMRstats(rawC[, Ts])
v <- v[order(v$log_Gene_Mean), ]


hvg10 <- v$log_Gene_VMR >
         v$log_PoissonVMR_median + 10 * v$IQR_of_logged_VMR


plot(v$log_Gene_Mean, v$log_Gene_VMR, pch = 20, cex=.1, col = "#00000090")
lines(v$log_Gene_Mean, v$log_PoissonVMR_median,
      lwd = 1.5, col = "orange")
lines(v$log_Gene_Mean, v$log_PoissonVMR_q75,
      lwd = 1.5, lty = "dashed", col = "orange")
lines(v$log_Gene_Mean,
      v$log_PoissonVMR_median + v$IQR_of_logged_VMR,
      lwd = 1.5, lty="dashed", col = "red")
points(v$log_Gene_Mean[hvg10], 
       v$log_Gene_VMR[hvg10], pch=20, col = "red")


```




```{r fig.height=9, fig.width=9}
hvgs_T   <- VMRstats(rawC[, Ts])
                 hvg_2IQR = getHVG(hvgs_T, IQRs = 2)
                 hvg_10IQR = getHVG(hvgs_T, IQRs = 10)


hvgs_all <- VMRstats(rawC)
```






# T cell HVGs
```{r}
normT <- apply( rawC[names(hvgs_T$hvg_2IQR), Ts], 2, function(col) {
  (sqrt(col+3/8)-sqrt(3/8)) / sqrt(sum(col))
})

pheatmap::pheatmap(normT[, c(sample(which(isCD4Tcell[Ts]), 300), which(isCD8Tcell[Ts]))], cluster_cols = F,
                   show_colnames =F)

# pca <- irlba::irlba(scale(t(normT)), nv = 10)
pc  <- prcomp((t(normT)), center = TRUE, scale. = TRUE)


d5 <- dist(scale(pc$x[, 1:5], center = T, scale = T))
d6 <- dist(scale(pc$x[, 1:6]))
d10 <- dist(scale(pc$x[, 1:10]))
d10_u <- dist(pc$x[, 1:10])

getUpper <- function(mat) mat[upper.tri(mat, diag = FALSE)]
  
  
distanceDF_Tcells <- function(dist) {
  rbind(
    data.frame(Group ="CD4_CD4",  
         Distance = getUpper( as.matrix(dist)[isCD4Tcell[Ts], isCD4Tcell[Ts]] ),
         stringsAsFactors = F),
    data.frame(Group = "CD4_CD8", 
         Distance = getUpper( as.matrix(dist)[isCD4Tcell[Ts], isCD8Tcell[Ts]] ),
         stringsAsFactors = F),
    data.frame(Group = "CD8_CD8", 
         Distance = getUpper( as.matrix(dist)[isCD8Tcell[Ts], isCD8Tcell[Ts]] ),
         stringsAsFactors = F)
   )
}



tsne_d10 <- Rtsne::Rtsne(as.matrix(d10), is_distance = TRUE)
plot(tsne_d10$Y[,1], tsne_d10$Y[,2], pch=20, col = 1 + isCD8Tcell[Ts])
```
```{r}
ggplot(distanceDF_Tcells(d10),
       aes(x = Distance, stat(density), fill = Group)) +
       geom_histogram(position = "identity", alpha = .6, binwidth = 1)
```







# Seurat: T cells

```{r}
library(Seurat)
s <- CreateSeuratObject(rawC[, Ts])
s <- MakeSparse(s)
s <- NormalizeData(s)
s <- FindVariableGenes(s, display.progress = F)
length(s@var.genes)
```
```{r}
s <- ScaleData(object = s, vars.to.regress = c("nUMI"))
s <- RunPCA(s, pc.genes = s@var.genes, do.print = F)
# s <- JackStraw(object = s, num.replicate = 100, display.progress = FALSE)
# JackStrawPlot(object =s, PCs = 1:12)
PCElbowPlot(s)
```

```{r, eval = F}
s <- FindClusters(object = s, reduction.type = "pca", dims.use = 1:10, 
    resolution = 0.6, print.output = 0, save.SNN = TRUE)
s <- RunTSNE(object = s, dims.use = 1:10, do.fast = TRUE)
```

```{r}
d_seurat <- parallelDist::parDist(s@dr$pca@cell.embeddings[, 1:10],
                                  threads = 4)
d_seurat_scaled <- parallelDist::parDist(scale(s@dr$pca@cell.embeddings[, 1:10]),
                                  threads = 4)

tsne_d <- Rtsne::Rtsne(as.matrix(d_seurat), is_distance = TRUE)
plot(tsne_d$Y[,1], tsne_d$Y[,2], pch=20, col = 1 + isCD8Tcell[Ts])
```
## Distances (Seurat, T cells)


```{r}
ggplot(distanceDF_Tcells(d_seurat),
       aes(x = Distance, stat(density), fill = Group)) +
       geom_histogram(position = "identity", alpha = .6, binwidth = 1)
```







```{r}
# save.image(file = "/home/felix/PhDother/scAnalysis/sc_methods/hvg/savepoint/1.rda")
load(file = "/home/felix/PhDother/scAnalysis/sc_methods/hvg/savepoint/1.rda")
```









# Play zone

```{r}
s <- MakeSparse(CreateSeuratObject(rawC[, Ts]))
s <- NormalizeData(s)
s <- FindVariableGenes(s, display.progress = F)
s@var.genes <- names(hvgs_T$hvg_2IQR)
s <- ScaleData(object = s, vars.to.regress = c("nUMI"),
               genes.use = s@var.genes,
               model.use = "negbinom", do.par = T, num.cores = 4, display.progress = T)
s <- RunPCA(s, pc.genes = s@var.genes, do.print = F)

d_seurat <- parallelDist::parDist(s@dr$pca@cell.embeddings[, 1:10],
                                  threads = 4)

ggplot(distanceDF_Tcells(d_seurat),
       aes(x = Distance, stat(density), fill = Group)) +
       geom_histogram(position = "identity", alpha = .6, binwidth = 1)
```





```{r}
rawC[ names(hvgs_all$hvg_10IQR), ]

cell1 <- 13
cell2 <- 97
genes <- names(hvgs_all$hvg_10IQR)
genes <- genes[! is.na(genes)]

C <- rawC[genes, Ts]
C <- t( t(rawC[genes, Ts]) / cs)

```


# weighted distance

```{r}

mat <- rawC[, Ts]
cs  <- colSums(mat)
mat <- mat[rownames(mat) %in% names(hvgs_T$hvg_2IQR) ,]

w <- apply(mat, 1, function(k) 1 / mean(1/ (k+.5)))

plot(w, col =
(1 + rownames(mat) %in% names(hvgs_T$hvg_2IQR) ))

d <- parDist(t(sqrt(w) * log( t(t(mat + .5) / cs)) ),
               threads = 4 )

ggplot(distanceDF_Tcells(d),
       aes(x = Distance, stat(density), fill = Group)) +
       geom_histogram(position = "identity", alpha = .6, binwidth = 1)

```








# Seurat's means and disps

FindVariableGenes by default uses ExpMean and LogVMR, which effectively do this
with the lognormalized values x:

```{r}
x  <- s@data["poisson_1305", ]
expMean <-  log(
              x = mean(x = exp(x = x) - 1) + 1 )

disp    <-  log(
              x = var(x = exp(x = x) - 1) / mean(x = exp(x = x) - 1) )



xf <- pCounts["poisson_1305", ]  / cs 

```

I find this worrying.


# Seurat on poisson genes

```{r}
library(Seurat)

s <- CreateSeuratObject(pCounts)
s <- NormalizeData(s)
s <- FindVariableGenes(s, display.progress = F)
length(s@var.genes)
```
Seurat finds 600 HVGs where there is no biological information at all.
```{r}
s <- ScaleData(object = s, vars.to.regress = c("nUMI"))
s <- RunPCA(s, pc.genes = s@var.genes, do.print = F)
s <- JackStraw(object = s, num.replicate = 100, display.progress = FALSE)
JackStrawPlot(object =s, PCs = 1:12)
```
```{r}
s <- FindClusters(object = s, reduction.type = "pca", dims.use = 1:7, 
    resolution = 0.6, print.output = 0, save.SNN = TRUE)
s <- RunTSNE(object = s, dims.use = 1:7, do.fast = TRUE)
TSNEPlot(s)
```

# Monocle on Poisson genes

```{r}
library(monocle)
pd <- new("AnnotatedDataFrame", data = data.frame(
  cellID = colnames(pCounts_small),
  row.names = colnames(pCounts_small)))
fd <- new("AnnotatedDataFrame",
          data.frame(gene_short_name= rownames(pCounts_small),
                 row.names=rownames(pCounts_small)))
cds_p <- newCellDataSet(Matrix(pCounts_small, sparse = T), phenoData = pd, featureData = fd,
                      expressionFamily = negbinomial.size())

pd <- new("AnnotatedDataFrame", data = data.frame(
  cellID = colnames(rawC_small),
  row.names = colnames(rawC_small)))
fd <- new("AnnotatedDataFrame",
          data.frame(gene_short_name= rownames(rawC_small), 
                 row.names=rownames(rawC_small)))
cds  <- newCellDataSet(Matrix(rawC_small, sparse = T), phenoData = pd, featureData = fd,
                      expressionFamily = negbinomial.size())




cds <- estimateSizeFactors(cds); cds <- estimateDispersions(cds)
cds_p <- estimateSizeFactors(cds_p); cds_p <- estimateDispersions(cds_p)
disp_table <- dispersionTable(cds)
disp_table_p <- dispersionTable(cds_p)


plot(disp_table$mean_expression, disp_table$dispersion_empirical, log="xy",
     pch=20, cex=.3, xlab = "Mean Expression", ylab="Empirical dispersion",
     col = "#00000090", # transparent black
     main="Monocle's dispersion estimates\nRed: simulated poisson genes")
points(disp_table_p$mean_expression, disp_table_p$dispersion_empirical, pch = 20, cex=.3, col="#ff000090")
```

We see that monocle could gain a lot by simply modelling poisson noise and
plotting it into their dispersion plot.











# End of Script

```{r}
devtools::session_info()
```


